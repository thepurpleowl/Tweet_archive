{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags:  [u'DEM', u'NN', u'PSP', u'PSP', u'NN', u'PSP', u'NN', u'PRP', u'NN', u'NN', u'PSP', u'JJ', u'NN']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "# implements viterbi algorithm\n",
    "\n",
    "import codecs\n",
    "from math import log\n",
    "import operator\n",
    "from collections import defaultdict,OrderedDict\n",
    "tags=[]\n",
    "def viterbi(sentence,Prb_dict,all_tags,D,Trns_P):\n",
    "\ttag_seq = []\n",
    "\tl = len(all_tags)\n",
    "\tall_tags = list(all_tags)\n",
    "\tstart_prob = log(1+1/l,2)\n",
    "\tDP_arr = [[0]*l for i in range(len(sentence))]\n",
    "\tOB_arr = [[0]*l for i in range(len(sentence))]\n",
    "\trows = len(sentence)\n",
    "\tcols = l\n",
    "\ti,j = 0,0\n",
    "\twhile i<rows:\n",
    "\t\tj = 0\n",
    "\t\twhile j<cols:\n",
    "\t\t\tif i==0:\n",
    "\t\t\t\tDP_arr[i][j] = start_prob + Prb_dict[sentence[i]+'|'+all_tags[j]]\n",
    "\t\t\telse:\n",
    "\t\t\t\tobt_frm = 0\n",
    "\t\t\t\tmax_val = -1*float('inf')\n",
    "\t\t\t\tfor k in range(cols):\n",
    "\t\t\t\t\tval = DP_arr[i-1][k]+Trns_P[k][j]\n",
    "\t\t\t\t\tif val>max_val:\n",
    "\t\t\t\t\t\tmax_val = val\n",
    "\t\t\t\t\t\tobt_frm = k\n",
    "\t\t\t\tDP_arr[i][j] = max_val+Prb_dict[sentence[i]+'|'+all_tags[j]]\n",
    "\t\t\t\tOB_arr[i][j] = obt_frm\n",
    "\t\t\tj += 1\n",
    "\t\ti += 1\n",
    "\t#res = [ DP_arr[-1].index(max(DP_arr[-1])) ] + [0]*(rows-1)\n",
    "\t#print res\n",
    "\tres = []\n",
    "\tlst = DP_arr[-1].index(max(DP_arr[-1]))\n",
    "\tres.append(lst)\n",
    "\tfor i in range(rows-1,0,-1):\n",
    "\t\tlst = OB_arr[i][lst]\n",
    "\t\tres.append(lst)\n",
    "\treturn [all_tags[i] for i in res[::-1]] \n",
    "\n",
    "def tag():\n",
    "\t__fTrain = codecs.open(\"train.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\t__fTest  = codecs.open(\"tagfile.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\t\n",
    "\tDict \t = defaultdict(int)\n",
    "\tPsb_tags = defaultdict(set)\n",
    "\t\n",
    "\ttag_pairs = []\n",
    "\tfor line in __fTrain.readlines():\n",
    "\t\ttokens = line.split()\n",
    "\t\ttags = []\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tword = token.split('|')[0].strip()\n",
    "\t\t\ttag  = token.split('|')[2].split('.')[0].strip(':?').strip()\n",
    "\t\t\tif (tag=='I-NP' or tag=='B-NP' or tag=='O'):\n",
    "\t\t\t\ttag='NN'\n",
    "\t\t\ttags.append(tag)\n",
    "\t\t\tDict[word+'|'+tag] += 1\n",
    "\t\t\tPsb_tags[word] = Psb_tags[word] | set([tag])\n",
    "\t\ttag_pairs.extend(zip(tags,tags[1:]))\n",
    "\n",
    "\tPrb_dict = defaultdict(int)\n",
    "\tall_tags = set([])\n",
    "\tfor word in Psb_tags:\n",
    "\t\ttags = Psb_tags[word]\n",
    "\t\tall_tags = all_tags | set(tags)\n",
    "\t\tvals = [Dict[word+'|'+i] for i in tags]\n",
    "\t\tprob = [log(1+i/sum(vals), 2) for i in vals]\n",
    "\t\tfor i in zip(tags,prob):\n",
    "\t\t\tPrb_dict[word+'|'+i[0]] = i[1]\n",
    "\n",
    "\tD = {v: k for k, v in OrderedDict(enumerate(all_tags)).iteritems()}\n",
    "\tTrns_prob = [[0]*len(all_tags) for i in range(len(all_tags))]\n",
    "\tfor i in tag_pairs:\n",
    "\t\tTrns_prob[ D[i[0]] ][ D[i[1]] ] += 1\n",
    "\tTrns_P = [[0]*len(all_tags) for i in range(len(all_tags))]\n",
    "\ti=0\n",
    "\twhile i<len(all_tags):\n",
    "\t\tj=0\n",
    "\t\twhile j<len(all_tags):\n",
    "\t\t\tTrns_P[i][j] = Trns_prob[i][j]/sum(Trns_prob[i])\n",
    "\t\t\tj += 1\n",
    "\t\ti += 1\n",
    "\tsorted_D = sorted(D.items(), key=operator.itemgetter(1))\n",
    "\t__fTrain.close()\n",
    "\n",
    "\t__fTrain = codecs.open(\"train.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\tfor line in __fTest.readlines():\n",
    "\t\ttry:\n",
    "\t\t\ttokens = line.split()\n",
    "\t\t\ttags = []\n",
    "\t\t\tsentence = []\n",
    "\t\t\tfor token in tokens:\n",
    "\t\t\t\tword = token.split('|')[0].strip()\n",
    "\t\t\t\tsentence.append(word)\n",
    "\t\t\ttag_seq = viterbi(sentence,Prb_dict,all_tags,D,Trns_P)\n",
    "\t\t\ttags=tag_seq\n",
    "\t\t\tprint 'Tags: ',tag_seq\n",
    "\t\texcept:\n",
    "\t\t\tprint \"Couldn't tag sentence ...\"\n",
    "\t\t\tcontinue\n",
    "\n",
    "def test():\n",
    "\t__fTrain = codecs.open(\"train.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\t__fTest  = codecs.open(\"test.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\n",
    "\tDict \t = defaultdict(int)\n",
    "\tPsb_tags = defaultdict(set)\n",
    "\n",
    "\ttag_pairs = []\n",
    "\tfor line in __fTrain.readlines():\n",
    "\t\ttokens = line.split()\n",
    "\t\ttags = []\n",
    "\t\tfor token in tokens:\n",
    "\t\t\tword = token.split('|')[0].strip()\n",
    "\t\t\ttag  = token.split('|')[2].split('.')[0].strip(':?').strip()\n",
    "\t\t\tif (tag=='I-NP' or tag=='B-NP' or tag=='O'):\n",
    "\t\t\t\ttag='NN'\n",
    "\t\t\ttags.append(tag)\n",
    "\t\t\tDict[word+'|'+tag] += 1\n",
    "\t\t\tPsb_tags[word] = Psb_tags[word] | set([tag])\n",
    "\t\ttag_pairs.extend(zip(tags,tags[1:]))\n",
    "\n",
    "\tPrb_dict = defaultdict(int)\n",
    "\tall_tags = set([])\n",
    "\tfor word in Psb_tags:\n",
    "\t\ttags = Psb_tags[word]\n",
    "\t\tall_tags = all_tags | set(tags)\n",
    "\t\tvals = [Dict[word+'|'+i] for i in tags]\n",
    "\t\tprob = [log(1+i/sum(vals), 2) for i in vals]\n",
    "\t\tfor i in zip(tags,prob):\n",
    "\t\t\tPrb_dict[word+'|'+i[0]] = i[1]\n",
    "\n",
    "\tD = {v: k for k, v in OrderedDict(enumerate(all_tags)).iteritems()}\n",
    "\tTrns_prob = [[0]*len(all_tags) for i in range(len(all_tags))]\n",
    "\tfor i in tag_pairs:\n",
    "\t\tTrns_prob[ D[i[0]] ][ D[i[1]] ] += 1\n",
    "\tTrns_P = [[0]*len(all_tags) for i in range(len(all_tags))]\n",
    "\ti=0\n",
    "\twhile i<len(all_tags):\n",
    "\t\tj=0\n",
    "\t\twhile j<len(all_tags):\n",
    "\t\t\tTrns_P[i][j] = Trns_prob[i][j]/sum(Trns_prob[i])\n",
    "\t\t\tj += 1\n",
    "\t\ti += 1\n",
    "\tsorted_D = sorted(D.items(), key=operator.itemgetter(1))\n",
    "\t__fTrain.close()\n",
    "\n",
    "\t__fTrain = codecs.open(\"train.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "\tACC = 0\n",
    "\ttoks = 0\n",
    "\tTP = 0\n",
    "\tTN = 0\n",
    "\tFP = 0\n",
    "\tFN = 0\n",
    "\tfor line in __fTest.readlines():\n",
    "\t\ttry:\n",
    "\t\t\ttokens = line.split()\n",
    "\t\t\ttags = []\n",
    "\t\t\tsentence = []\n",
    "\t\t\tfor token in tokens:\n",
    "\t\t\t\tword = token.split('|')[0].strip()\n",
    "\t\t\t\tsentence.append(word)\n",
    "\t\t\t\ttag  = token.split('|')[2].split('.')[0].strip(':?').strip()\n",
    "\t\t\t\tif (tag=='I-NP' or tag=='B-NP' or tag=='O'):\n",
    "\t\t\t\t\ttag='NN'\n",
    "\t\t\t\ttags.append(tag)\n",
    "\t\t\ttag_seq = viterbi(sentence,Prb_dict,all_tags,D,Trns_P)\n",
    "\t\t\tacc = 0\n",
    "\t\t\ttemp_toks = 0\n",
    "\t\t\tfor i in zip(tag_seq,tags):\n",
    "\t\t\t\tif (i[0]==i[1] and i[0]!='UNK'):\n",
    "\t\t\t\t\tacc += 1\n",
    "\t\t\t\t\tACC += 1\n",
    "\t\t\t\t\tTP += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif (i[0]=='UNK' and i[1]=='UNK'):\n",
    "\t\t\t\t\t\tTN += 1\n",
    "\t\t\t\t\telif (i[0]=='UNK' and i[1]!='UNK'):\n",
    "\t\t\t\t\t\tFN += 1\n",
    "\t\t\t\t\telif (i[0]!='UNK' and i[1]=='UNK'):\n",
    "\t\t\t\t\t\tFP += 1\n",
    "\t\t\t\t\telif (i[0]!='UNK' and i[1]!='UNK'):\n",
    "\t\t\t\t\t\tFP += 1\n",
    "\t\t\t\ttoks += 1\n",
    "\t\t\t\ttemp_toks += 1 \n",
    "\t\t\tprint acc,temp_toks,acc/temp_toks\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\tprint ACC,toks,ACC/toks\n",
    "\tprint TP,FP,TN,FN\n",
    "\tprint \"Precision = \", TP/(TP+FP)\n",
    "\tprint \"Recall = \",TP/(TP+FN)\n",
    "\tprint \"Accuracy = \",(TP+TN)/(TP+FP+TN+FN)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\ttag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEM', 'NN', 'PSP', 'PSP', 'NN', 'PSP', 'NN', 'PRP', 'NN', 'NN', 'PSP', 'JJ', 'NN']\n"
     ]
    }
   ],
   "source": [
    "tags=[u'DEM', u'NN', u'PSP', u'PSP', u'NN', u'PSP', u'NN', u'PRP', u'NN', u'NN', u'PSP', u'JJ', u'NN']\n",
    "tags=[w.encode('utf-8') for w in tags]\n",
    "print tags\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import json,string,io,codecs\n",
    "with io.open(\"HSWN_WN.txt\",encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "score=0\n",
    "\n",
    "required_news=['समर्थन', 'हासिल', 'करने']\n",
    "lena=0;\n",
    "lenb=len(required_news);\n",
    "for line in content:\n",
    "    if(lena==lenb):\n",
    "        break\n",
    "    else:\n",
    "        words = line.split()\n",
    "        words=[ w.encode('utf-8') for w in words]\n",
    "        pscore=float(words[2])\n",
    "        nscore=float(words[3])\n",
    "        synonyms=words[4].split(',')\n",
    "        #print synonyms\n",
    "        for eachWord in synonyms:\n",
    "            for i in required_news:\n",
    "                if eachWord.decode('utf-8')==i.decode('utf-8'):\n",
    "                    score= score+ pscore-nscore\n",
    "                    lena=lena+1\n",
    "                else:\n",
    "                    pass\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Independent news scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.jagran.com/\"\n",
    "\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "#print r.status_code\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "# for link in soup.findAll('span',{'class':'tabtxt'}):\n",
    "#     print(link.getText()),'\\n'\n",
    "# for link in soup.findAll('div',{'id':'w1486637789076'}):\n",
    "#     for inner in soup.findAll('div',{'class':'breakinglistingholder'}):\n",
    "#         for head in soup.findAll('h3'):\n",
    "#             print head,'\\n'\n",
    "file=open('news.txt','w')\n",
    "c=0\n",
    "for link in soup.findAll('h2'):\n",
    "    if len(link.getText()):\n",
    "        c=c+1\n",
    "        file.write(link.getText().encode('utf-8'))\n",
    "        #print(link.getText()),'\\n'\n",
    "for link in soup.findAll('h3'):\n",
    "    if len(link.getText()):\n",
    "        c=c+1\n",
    "        file.write(link.getText().encode('utf-8'))\n",
    "        #print(link.getText()),'\\n'\n",
    "for link in soup.findAll('h4'):\n",
    "    if len(link.getText()):\n",
    "        c=c+1\n",
    "        file.write(link.getText().encode('utf-8'))\n",
    "        #print(link.getText()),'\\n'\n",
    "\n",
    "#for link in soup.findAll('span',{'class':'tabtxt'}):\n",
    "#     print(link.getText()),'\\n'\n",
    "        \n",
    "selected_news=[]\n",
    "required_news=['बाहुबली2','पबाहुबली']\n",
    "\n",
    "# import codecs\n",
    "# f = codecs.open('news.txt','r3',encoding='utf-8')\n",
    "f = open('news.txt','r')\n",
    "import nltk\n",
    "count=0\n",
    "for line in f.read().split(' '.encode('utf-8')):\n",
    "    #print type(line)\n",
    "    news_words=line.decode('utf-8').split(' ')\n",
    "    #print news_words\n",
    "    \n",
    "    valid=False\n",
    "    for word in required_news:\n",
    "        if word.decode('utf-8') in news_words:\n",
    "            valid=True\n",
    "    if(valid==True):\n",
    "        print line\n",
    "        count=count+1\n",
    "\n",
    "print c\n",
    "print count\n",
    "## enter code checking keywords\n",
    "\n",
    "##code for situation and polarity\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Independent tweets through streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "जीता\n",
      "\n",
      "'बाहुबली2'\n",
      "जीता\n",
      "\n",
      "'बाहुबली2'\n",
      "खुलासा'बाहुबली2'\n",
      "'ट्यूबलाइट''बाहुबली2'\n",
      "शख़्स'बाहुबली2'\n"
     ]
    }
   ],
   "source": [
    "f = open('news.txt','r')\n",
    "for line in f.read().split(' '):\n",
    "    #print line.decode('utf-8')\n",
    "    if 'बाहुबली2' in line:\n",
    "        print line\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json,string,io,codecs\n",
    "model={}\n",
    "model2={}\n",
    "with io.open(\"HSWN_WN.txt\",encoding=\"utf-8\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    words = line.split()\n",
    "    pscore=float(words[2])\n",
    "    nscore=float(words[3])\n",
    "    synonyms=words[4].split(',')\n",
    "#     for synonym in synonyms:\n",
    "#         print synonym.encode('utf-8')\n",
    "    for eachWord in synonyms:\n",
    "        if eachWord not in model:\n",
    "            check=abs(pscore-nscore)\n",
    "            if check>=0.1:\t#can change\n",
    "                if pscore>nscore:\n",
    "                    tag=1\n",
    "                else:\n",
    "                    tag=-1\n",
    "            else:\n",
    "                tag=0\n",
    "            model[eachWord]=tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "हे बिहार के सबसे बड़े मॉल की मिट्टी ! बिहार को तुमपर गर्व है,तुमने बिहार के सबसे बड़े राजनीतिक घराने की क्षुधा शांत कर अपना धर्म निभाया है।pic.twitter.com/G1oeM0Tqrk \n",
      "\n",
      "हमारी माता हमे दो से तीन साल तक दूध पिलाती है, परंतु गौमाता हमे जीवन पर्यन्त दूध पिलाती है, इसलिए गौमाता का स्थान माता से भी ऊंची है।  \n",
      "\n",
      "उसने अब तक मुझे ये सिखाया कि हत्यारों और आतंकियों का कोई धर्म नहीं होता\n",
      "फिर कल बताया गौरक्षा के नाम पर हत्या करने वाले हिन्दू हैं. \n",
      "\n",
      "Idhikolhah echeh bunaa konme meehaku jalah laigen verikan kuran furusathu libenee e furusathu dheythee. Salaamathee baaruthah zinma nangavaa \n",
      "\n",
      "Maamigileege rayyithunge hivvarah saabas aruvan. Hurihaa rashehgaves e rayyithehge khiyaalu thakah ihthijaaj kuriyah gendhanvee. \"Kakkanvee\" \n",
      "\n",
      "जिन्दगी भर कोई साथ नहीं देता यह जान लिया हमने\n",
      "लोग तो तब याद करते हैं जब वह खुद अकेले होंpic.twitter.com/4GQtfLbyj9 \n",
      "\n",
      "नमामि मोक्षदाता \n",
      "सारी दुनिया डरती हे तेरे विकराल रूप से तुझे सत सत कोटि वंदन में दास तेरा तेरे चरणों में मेरा शीश वंदन हर हर महादेवpic.twitter.com/m3rCspteFv \n",
      "\n",
      "तीन बातें करो -\n",
      "उत्तम के साथ संगीत,\n",
      "विद्वान् के साथ वार्तालाप और\n",
      "सहृदय के साथ मैत्री \n",
      "\n",
      "तीन के आंसू पवित्र होते हैं - \n",
      "प्रेम के,\n",
      "करुना के और\n",
      "सहानभूति के \n",
      "\n",
      "तीन बातें सुखी जीवन के लिए -\n",
      "अतीत की चिंता मत करो,\n",
      "भविष्य का विश्वास न करो और\n",
      "वर्तमान को व्यर्थ मत जाने दो \n",
      "\n",
      "तीन चीजें किसी भी इंसान को बर्बाद कर सकती है - शराब,\n",
      "घमन्ड और\n",
      "क्रोध \n",
      "\n",
      "तीनों चीजों को हमेशा वश में रखो -\n",
      "मन,\n",
      "काम और\n",
      "लोभ \n",
      "\n",
      "Shuo Shipic.twitter.com/JluPZ60XPk \n",
      "\n",
      "राष्ट्रवादी प्रदीप जी @thepradeep01 को 6K फालोवर की बधाइयाँpic.twitter.com/d8jQFOcPDO \n",
      "\n",
      "Dubaipic.twitter.com/pOxHq1BaOY \n",
      "\n",
      "कश्मीर बाढ़ के लिए परेशान मत हो, तुम हरामी लोग बस पत्थरबाज़ी करो, पाकिस्तान जिंदाबाद हिंदुस्तान मुर्दाबाद, बोलो देखो सब ठीक हो जाएगा  \n",
      "\n",
      "गूगल से इमेज, शायरी  GIF वगैरह डाउनलोड कर; थोक में ट्विटर पर चेंपने वालों के लिए दुखद सूचना - अब चार्ज लगेगा\n",
      "\n",
      "काश ऐसा हो  \n",
      "\n",
      "गौ रक्षकों के हाथों एक मुसलमान क्या मरा भांड मीडिया की बोलती चालू ये तब कहाँ होते जब RSS और BJP कार्यकर्ताओं को केरल में रोज मारा जा रहा  \n",
      "\n",
      "गाय को माता मानते हो\n",
      "वो आप की आस्था की बात है \n",
      "इंसानों को इंसान मानना कब शुरू करोगे?\n",
      "#GauRakshakTerror \n",
      "\n",
      "हर एक जज्बात को जुबान नहीं मिलता\n",
      "\n",
      "ईश्क के राहगुजर को मकान नहीं मिलता\n",
      "\n",
      "फिर भी चलते है इसकी तलास में\n",
      "\n",
      "जानते हुए कि इस डगर को मुकाम नहीं मिलता \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://twitter.com/search?l=hi&q=since%3A2017-04-06%20until%3A2017-04-07&src=typd&lang=en\"\n",
    "\n",
    "r  = requests.get(url)\n",
    "data = r.text\n",
    "print r.status_code\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "for link in soup.findAll('p',{'class':'TweetTextSize js-tweet-text tweet-text'}):\n",
    "    print(link.getText()),'\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "420\n",
      "420\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='stream.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/filter.json?delimited=length (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f28d4304490>: Failed to establish a new connection: [Errno 110] Connection timed out',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d734b9258181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m#This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/surya/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, follow, track, async, locations, stall_warnings, languages, encoding, filter_level)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'delimited'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'stream.twitter.com'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     def sitestream(self, follow, stall_warnings=False,\n",
      "\u001b[1;32m/home/surya/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_start\u001b[1;34m(self, async)\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/surya/anaconda2/lib/python2.7/site-packages/tweepy/streaming.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# call a handler first so that the exception can be logged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='stream.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/filter.json?delimited=length (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f28d4304490>: Failed to establish a new connection: [Errno 110] Connection timed out',))"
     ]
    }
   ],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API \n",
    "consumer_key = 'tyEoyqfYZ83MxJIpvoRDFsIAH'\n",
    "consumer_secret = 'LHPqcgb4hmPLilW840PIeiqfMT45pxvweLmsr4s6Hpm7E2kJMq'\n",
    "access_token = '3290927268-JLojcEej6ld0PMZisFuF5f97WlmnRV8KjgYFbgn'\n",
    "access_token_secret = 'e4jhkXoQkv5AmjiyCPLuligJCHQC55Tc2hNJUZDWpSuFX'\n",
    "\n",
    "\n",
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        print data\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "\n",
    "        \n",
    "#This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "l = StdOutListener()\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "stream = Stream(auth, l)\n",
    "\n",
    "str='बाहुबली'\n",
    "str=str.decode('utf-8')\n",
    "#This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\n",
    "stream.filter(languages=['hi'],track=[str])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking  hindi similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दिल्ली में हैं\n",
      "true\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "str='दिल्ली में हैं'\n",
    "l=str.decode('utf-8')\n",
    "print l\n",
    "required_news=['दिल्ली','हैं']\n",
    "for i in required_news:\n",
    "    if i.decode('utf-8') in l:\n",
    "        print 'true'\n",
    "    else:\n",
    "        print 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
